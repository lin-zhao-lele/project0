import os
import json
import sys

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import torch
import joblib
from utils import create_sequences, build_model
from sklearn.metrics import mean_squared_error, r2_score
from module.visualization.pltTrend import plot_trend_signals_from_csv


# ========== è·¯å¾„é…ç½® ==========
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(BASE_DIR)
DATA_DIR = os.path.join(os.path.dirname(PROJECT_ROOT), "data", "processed")
RESULTS_DIR = os.path.join(PROJECT_ROOT, "predictors", "results")


def resolve_path(path_str, base="project"):
    if os.path.isabs(path_str):
        return os.path.normpath(path_str)
    if base == "project":
        return os.path.normpath(os.path.join(PROJECT_ROOT, path_str))
    elif base == "script":
        return os.path.normpath(os.path.join(BASE_DIR, path_str))
    elif base == "data":
        return os.path.normpath(os.path.join(DATA_DIR, path_str))

# ========== åŠ è½½é…ç½® ==========
config_path = os.path.join(PROJECT_ROOT, "predictors", "resource", "FinalModel_LSTM_args.json")
with open(config_path, "r", encoding="utf-8") as f:
    config = json.load(f)

predict_path = resolve_path(config["predict"], base="data")
predict_length = config.get("predict_length", 5)
window_size = config["params"]["window_size"]
hidden_units = config["params"]["hidden_units"]

# ========== åŠ è½½Scalerå’Œæ¨¡åž‹ ==========
x_scaler = joblib.load(os.path.join(PROJECT_ROOT, "predictors", "resource", "scalerX.joblib"))   # 12ç»´ç‰¹å¾å½’ä¸€åŒ–å™¨
y_scaler = joblib.load(os.path.join(PROJECT_ROOT, "predictors", "resource", "scalerY.joblib"))   # closeå½’ä¸€åŒ–å™¨

model_path = resolve_path(os.path.join(PROJECT_ROOT, "predictors", "resource", "FinalModel_LSTM.pt"), base="script")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ========== æ•°æ®é¢„å¤„ç† ==========
def preprocess_predict_data(path):
    df = pd.read_csv(path).sort_values("trade_date")

    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ç­‰
    df["ma5"] = df["close"].rolling(window=5).mean()
    df["ma10"] = df["close"].rolling(window=10).mean()
    df["return_1d"] = df["close"].pct_change(1)
    df["vol_ma5"] = df["vol"].rolling(window=5).mean()
    df = df.dropna().reset_index(drop=True)

    feature_cols = ['open', 'high', 'low', 'vol', 'amount',
                    'turnover_rate', 'turnover_rate_f', 'volume_ratio',
                    'ma5', 'ma10', 'return_1d', 'vol_ma5']

    X_raw = df[feature_cols].values  # 12ç»´ç‰¹å¾
    y_raw = df[["close"]].values     # 1ç»´close

    X_scaled = x_scaler.transform(X_raw)
    y_scaled = y_scaler.transform(y_raw)

    # æ‹¼æŽ¥æˆ13ç»´æ•°ç»„ï¼Œè·Ÿè®­ç»ƒæ—¶è¾“å…¥æ ¼å¼ä¸€è‡´
    full_input = np.hstack([X_scaled, y_scaled])

    df["scaled_close"] = y_scaled.flatten()

    return full_input, df

# ========== æ»šåŠ¨é¢„æµ‹ ==========
def rolling_forecast(last_window, predict_len):
    """
    last_window: numpyæ•°ç»„ï¼Œshape=(window_size, 13)ï¼Œæœ€åŽä¸€åˆ—æ˜¯closeå½’ä¸€åŒ–å€¼
    predict_len: intï¼Œé¢„æµ‹å¤©æ•°
    """
    predictions = []
    current_seq = last_window.copy()

    for _ in range(predict_len):
        inp = torch.tensor(current_seq[np.newaxis, :, :], dtype=torch.float32).to(device)  # shape (1, window_size, 13)
        with torch.no_grad():
            pred = model(inp).cpu().numpy().flatten()[0]

        predictions.append(pred)

        # ç”Ÿæˆä¸‹ä¸€æ­¥è¾“å…¥åºåˆ—ï¼šçª—å£æ»‘åŠ¨1æ­¥ï¼Œæœ€åŽä¸€è¡Œcloseç”¨é¢„æµ‹å€¼æ›¿æ¢
        next_input = current_seq[-1].copy()
        current_seq = np.vstack([current_seq[1:], next_input])
        current_seq[-1, -1] = pred  # æ›¿æ¢closeåˆ—

    return np.array(predictions)

# ========== ä¸»æµç¨‹ ==========
full_input, df_all = preprocess_predict_data(predict_path)  # 13ç»´è¾“å…¥

input_size = full_input.shape[1]  # åº”è¯¥æ˜¯13
model = build_model(input_shape=(window_size, input_size), hidden_units=hidden_units).to(device)
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()

# åˆ›å»ºåºåˆ—ç”¨äºŽå·²æœ‰æ•°æ®çš„é¢„æµ‹å’Œè¯„ä¼°
X_seq, _ = create_sequences(full_input, window_size)
X_seq_t = torch.tensor(X_seq, dtype=torch.float32).to(device)

with torch.no_grad():
    y_pred_scaled = model(X_seq_t).cpu().numpy().flatten()

# åå½’ä¸€åŒ–é¢„æµ‹ç»“æžœ
y_pred_inv = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()

# çœŸå®žcloseåºåˆ—ï¼ˆä»Žç¬¬window_sizeå¼€å§‹å¯¹åº”é¢„æµ‹çš„yï¼‰
y_true_scaled = df_all["scaled_close"].values[window_size:]
y_true_inv = y_scaler.inverse_transform(y_true_scaled.reshape(-1, 1)).flatten()

dates = df_all["trade_date"].values[window_size:]

# ========== è®¡ç®—è¯„ä¼°æŒ‡æ ‡ ==========
mse = mean_squared_error(y_true_inv, y_pred_inv)
r2 = r2_score(y_true_inv, y_pred_inv)
print(f"[å·²æœ‰æ•°æ®] MSE: {mse:.4f}")
print(f"[å·²æœ‰æ•°æ®] RÂ²: {r2:.4f}")

df_out = pd.DataFrame({
    "trade_date": dates,
    "true_close": y_true_inv,
    "predicted_close": y_pred_inv
})

# è¿½åŠ é¢„æµ‹æœªæ¥Nå¤©
print(f"ðŸ”„ è¿½åŠ é¢„æµ‹æœªæ¥ {predict_length} å¤©")
last_window = full_input[-window_size:]  # å–æœ€åŽä¸€ä¸ªçª—å£ï¼ŒåŒ…å«13ç»´
pred_scaled_future = rolling_forecast(last_window, predict_length)
pred_inv_future = y_scaler.inverse_transform(pred_scaled_future.reshape(-1, 1)).flatten()

last_date = pd.to_datetime(df_all["trade_date"].iloc[-1], format="%Y%m%d")
future_dates = [(last_date + pd.Timedelta(days=i+1)).strftime("%Y%m%d") for i in range(predict_length)]

df_future = pd.DataFrame({
    "trade_date": future_dates,
    "predicted_close": pred_inv_future
})

df_all_out = pd.concat([df_out, df_future], ignore_index=True)

# ========== ä¿å­˜ç»“æžœ ==========
os.makedirs(resolve_path("results", base="script"), exist_ok=True)
save_path = resolve_path("results/lstm_inference_output.csv", base="script")
df_all_out.to_csv(save_path, index=False)
print(f"âœ… æŽ¨ç†ç»“æžœä¿å­˜è‡³ {save_path}")

# ========== ç»˜å›¾ ==========
df_all_out["trade_date"] = pd.to_datetime(df_all_out["trade_date"], format="%Y%m%d")
plt.figure(figsize=(10, 4))

if "true_close" in df_all_out.columns:
    plt.plot(df_all_out["trade_date"], df_all_out["true_close"], label="True Close")
plt.plot(df_all_out["trade_date"], df_all_out["predicted_close"], label="Predicted Close")

plt.xlabel("Date")
plt.ylabel("Close Price")
plt.title("LSTM Inference Prediction with Future Forecast")
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plot_path = resolve_path("results/lstm_inference_plot.png", base="script")
plt.savefig(plot_path)
print(f"ðŸ“Š æŽ¨ç†å›¾ä¿å­˜è‡³ {plot_path}")


# é˜ˆå€¼ï¼šé¢„æµ‹æ¶¨è·Œå¹…å°äºŽè¯¥å€¼æ—¶å¿½ç•¥ä¿¡å·ï¼ˆå•ä½ï¼šç™¾åˆ†æ¯”ï¼‰
threshold_pct = 0.03  # 0.5%

# è¯»å–é¢„æµ‹æ–‡ä»¶
pred_df = pd.read_csv(os.path.join(RESULTS_DIR, "lstm_inference_output.csv"))

# è®¡ç®—é¢„æµ‹æ¶¨è·Œå¹…
pred_df["predicted_change"] = pred_df["predicted_close"].diff() / pred_df["predicted_close"].shift(1)
pred_df["true_change"] = pred_df["true_close"].diff() / pred_df["true_close"].shift(1)

# ç”Ÿæˆé¢„æµ‹è¶‹åŠ¿ä¿¡å·ï¼ˆ1 = ä¸Šæ¶¨ï¼Œ-1 = ä¸‹è·Œï¼Œ0 = æ— æ“ä½œï¼‰
pred_df["trend_signal"] = 0
pred_df.loc[pred_df["predicted_change"] > threshold_pct, "trend_signal"] = 1
pred_df.loc[pred_df["predicted_change"] < -threshold_pct, "trend_signal"] = -1

# ç”ŸæˆçœŸå®žè¶‹åŠ¿æ–¹å‘ï¼ˆç”¨äºŽéªŒè¯ï¼‰
pred_df["true_trend"] = 0
pred_df.loc[pred_df["true_change"] > 0, "true_trend"] = 1
pred_df.loc[pred_df["true_change"] < 0, "true_trend"] = -1

# è®¡ç®—è¶‹åŠ¿æ–¹å‘å‡†ç¡®çŽ‡
valid_mask = pred_df["trend_signal"] != 0
accuracy = (pred_df.loc[valid_mask, "trend_signal"] == pred_df.loc[valid_mask, "true_trend"]).mean()

print(f"è¶‹åŠ¿ä¿¡å·å‡†ç¡®çŽ‡ï¼ˆè¿‡æ»¤å°æ³¢åŠ¨åŽï¼‰: {accuracy:.2%}")
print(f"æ€»ä¿¡å·æ•°: {valid_mask.sum()} æ¡")

# ä¿å­˜ä¿¡å·æ–‡ä»¶
trend_path = os.path.join(RESULTS_DIR, "lstm_inference_trend_signals.csv")
pred_df.to_csv(trend_path, index=False)
print(f"è¶‹åŠ¿ä¿¡å·å·²ä¿å­˜åˆ° {trend_path}")

plot_trend_signals_from_csv(trend_path, os.path.join(RESULTS_DIR, "lstm_inference_trend_signals_plot.png"))
